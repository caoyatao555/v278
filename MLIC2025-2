@Proceedings{MLIC-2025,
    booktitle = {Proceedings of 2025 2nd International Conference on Machine Learning and Intelligent Computing},
    name = {International Conference on Machine Learning and Intelligent Computing},
    shortname = {MLIC},
    editor = {Zeng, Nianyin and Pachori, Ram Bilas and Wang, Dongshu},
    volume = {278},
    year = {2025},
    start = {2025-04-25},
    end = {2025-04-27},
    conference_url = {https://www.icmlic.org},
    address = {Zhengzhou, China},
    note = {This volume contains 89 articles.}
}

@InProceedings{mlic25-46,
    title = {Ground States of Mixed Local and Nonlocal System of Choquard Type},
    author = {Cheng, Xiaohong and Deng, Zhiying},
    pages = {414-420},
    abstract = {This paper establishes the existence of solution for a family of weakly coupled nonlinear Choquard-type system. We apply variational methods and utilize the introduced manifold  $\mathcal{N}_{\omega}  $ to investigate this problem.}
}


@InProceedings{mlic25-47,
    title = {Research on Multi-population Quantum Genetic Algorithm Based on Optimal Computation Allocation Technology},
    author = {Guo, Ziyuan},
    pages = {421-426},
    abstract = {Quantum genetic algorithms have proven their unique superiority in dealing with stochastic optimization problems. In this paper, we propose an innovative multi-population quantum genetic algorithm, which is based on optimal computational resource allocation techniques. By carefully optimizing the initialization strategy of the population and introducing the concept of an elite population, combined with optimal computational resource allocation techniques, we have significantly improved the performance of the algorithm on stochastic optimization problems. After a series of experimental verifications, we found that the proposed algorithm surpasses traditional quantum genetic algorithms and other classical optimization algorithms in terms of convergence speed and solution accuracy.}
}



@InProceedings{mlic25-48,
    title = {An Inexact Golden Ratio Primal-Dual Algorithm for a Saddle Point Problem},
    author = {Liu, Jinxiu and Fang, Changjie and Qiu, Jingtao},
    pages = {427-433},
    abstract = {Convex optimization problems have wide applications in many fields such as mathematics, finance, industrial engineering, and management science. The primal dual algorithm (PDA), which is a classical approach for tackling a certain class of convex-concave saddle point problems, still has shortcomings such as fixed step size and difficulty in accurately solving certain subproblems. Therefore, designing more efficient inexact algorithms to solve these problems has important practical significance. During this investigation, we introduce an inexact golden ratio primal-dual algorithm based on the absolute error criteria of non-negative summable sequences. We establish the global convergence and the $O(1/N)$ rate of convergence for the proposed inexact algorithm, and the effectiveness of the proposed algorithm is verified by the image restoration experiment.}
}




@InProceedings{mlic25-49,
    title = {Directional Risk-Averse Integrated Loss Strategy for Time Series},
    author = {Fu, Qixuan and Chen, Xi and Liu, Chao and Ding, Xiaosong},
    pages = {434-439},
    abstract = {This study focuses on time series forecasting for risk-averse decision-makers, emphasizing trend direction over precise numerical predictions. Traditional methods like MSE fail to capture directional accuracy, which is crucial for risk-averse decisions. While techniques like DILATE improve time alignment, they still rely on numerical metrics. We introduce DRAILS (Directional Risk-Averse Integrated Loss Strategy for time series), a novel loss function that prioritizes directional accuracy while maintaining numerical precision. By incorporating a dynamic reward-penalty system inspired by the newsvendor model, DRAILS minimizes directional errors. Our experiments have shown that DRAILS outperforms existing methods in directional accuracy while maintaining competitive numerical results.}
}



@InProceedings{mlic25-50,
    title = {Research on Data Mining Techniques Based on DeepSeek-R1},
    author = {Cai, Lei and Yin, Fan and Meng, Xianbo},
    pages = {440-452},
    abstract = {With the rapid development of artificial intelligence technology, data mining, as one of its important application fields, is facing new opportunities and challenges. DeepSeek-R1, as an advanced pre-trained model, provides new technical means for data mining with its powerful feature extraction capabilities and efficient inference performance. This paper systematically investigates data mining techniques based on DeepSeek-R1, offering a comprehensive exploration of technical principles, application methods, and performance optimization. Experimental results demonstrate that DeepSeek-R1 exhibits significant performance advantages in data mining tasks, and corresponding optimization strategies are proposed. The research in this paper not only enriches the theoretical system of data mining technology but also provides valuable references for practical applications.}
}


@InProceedings{mlic25-51,
    title = {Viral Load-Driven Modeling of Epidemic Spread in Networks},
    author = {Yang, Tingxuan},
    pages = {453-460},
    abstract = {This paper studies epidemic transmission in scale-free networks using an SIS model with viral load-dependent infectivity. A network disease model is developed and analyzed via HMF theory, deriving the basic reproduction number   and its link to equilibrium stability. Simulations showing how viral load, network heterogeneity, and scale jointly affect transmission. Experiments indicate that:  High-er initial viral load   increases infection prevalence; larger degree exponent reduces infection due to low-degree node ``transmission dead ends"; infection grows with network size in scale-free networks.}
}




@InProceedings{mlic25-52,
    title = {Urat: Universal regularized adversarial training in robust reinforcement learning},
    author = {Chen, Jingtang and Chen, Haoxiang and Niu, Zilin and Zhu, Yi},
    pages = {461-475},
    abstract = {With the increasing maturity of reinforcement learning (RL)technology, its application areas have been widely expanded to several cutting-edge scientific fields, such as artificial intelligence, robotics, intelligent manufacturing, self-driving cars, and cognitive computing. However, the complexity and uncertainty of the real world pose serious challenges to the stability of RL models. For example, in the field of autonomous driving, unpredictable road conditions and variable weather conditions can adversely affect the decision-making process of intelligent driving algorithms, leading them to make irrational decisions. To address this problem, this study proposes a training method called Universal Regularized Adversarial Training in Robust Reinforcement Learning (Urat), which aims to enhance the robustness of the robustness of DRL strategies against potential adversarial attacks. In this study, we introduce a powerful attacker for targeted adversarial training of DRL intelligence. In addition, we innovatively incorporate a robust strategy regularizer into the algorithm to facilitate the learning of strategies by intelligences that can effectively defend against various attacks. The methods in this study have been tested adversarially in several OpenAI Gym  environments, including  HalfCheetah-v4, Swimmer-v4, and  Arcbot-vl.The  test  results show that the Urat training method can effectively improve the robustness of DRL strategies and achieve robust performance in complex and uncertain environments. This research result not only provides a new perspective in the field of reinforcement learning but also provides theoretical support and technical guarantee for intelligent decision-making in practical application scenarios such as autonomous driving.}
}



@InProceedings{mlic25-53,
    title = {SDE for Olympic selection Based on Dynamic Bayesian Network},
    author = {Chen, Si and Peng, Xiang and Xu, Shixuan},
    pages = {476-482},
    abstract = {This paper concentrates on the evaluation of Sports, Disciplines, or Events (SDEs) for Olympic selection. It presents a comprehensive approach that integrates multiple methods. The Dynamic Bayesian Network (DBN) is at the core, supplemented by data collection, normalization, and the TOPSIS method. This approach allows for a systematic assessment of SDEs, taking into account various criteria such as popularity, gender equity, and sustainability. The model's outcomes provide valuable predictions for future Olympic SDE selection, and sensitivity analyses confirm its stability. The research proposes a data-centric approach for the International Olympic Committee (IOC) to refine and enhance the Olympic sports program, leveraging insights from AI and analytics.}
}


@InProceedings{mlic25-54,
    title = {Forest to Agriculture: Based on The Lotka-Volterra Ecosystem Model},
    author = {Hou, Yanxu and Wang, Zike and Yin, Yuhuan and Zhang, Yujie},
    pages = {483-490},
    abstract = {As people's demand for land continues to grow, large areas of land have been reclaimed for agricultural production. As forests recede and soils change, chemicals begin to appear on farmland, and the original ecological relationships in the forest gradually evolve into a food chain driven by human activity. In this article, we established an agricultural ecological model based on Lotka-Volterra to analyze the interactions between different biological populations.

First, We construct the Lotka-Volterra model based on the producer and multi-stage consumer model, determine how different species are related to each other. Second, we introduce decomposers and peregrine falcons (tertiary consumers) into the model to reflect the reappearance of species. We derive the corresponding equations and use the fourth-order Runge-Kutta method to calculate each population's rate of change. Third, we added bats to the food web model and considered their role in insect hunting and pollination to analyze their impact. Finally, we performed a sensitivity analysis of the model, changing four survival conditions. For a given range of data, the number of organism populations eventually plateaued. This validates the sensitivity of the model and confirms the stability of organic agro-ecology.}
}


@InProceedings{mlic25-55,
    title = {Study on Wavelet Convolution-Based Underwater Image Denoising},
    author = {Li, Wei and Xie, Haiyan and Li, Jiaxi},
    pages = {491-497},
    abstract = {The processing of underwater images is critical for marine science, seafloor mapping, and underwater rescue operations. However, underwater optical images often suffer from poor quality due to light absorption and scattering caused by suspended particles. Additionally, due to technical limitations and environmental interference, underwater robots often capture images where light has been reflected and refracted multiple times before reaching the camera, further exacerbating noise. To address these challenges, this paper proposes an innovative underwater image processing model that combines wavelet convolution and dilated convolution for noise reduction. The model employs wavelet transformation to decompose images into high- and low-frequency components for preliminary processing, followed by the use of dilated convolution to extract noise and image features. This approach effectively removes noise from underwater images. Experimental results demonstrate that this method can adaptively handle illumination and detail information across different scales, addressing challenges such as uneven lighting, low contrast color distortion, and suspended particle noise. The processed images exhibit significantly improved clarity and contrast, even in complex underwater environments.}
}

@InProceedings{mlic25-56,
    title = {Research on interpretable methods for detecting elongated objects in power operations},
    author = {Li, Miao and Liu, Yanxia},
    pages = {498-510},
    abstract = {  Power operations take place in high-risk environments, such as high voltage and strong magnetic fields, making standardized procedures crucial. Employing object detection technology to monitor operational compliance enhances electrical safety. However, the presence of numerous elongated objects and background columnar interferences in power operation datasets significantly affects detection accuracy. To address this issue, we explore model structure improvements from an interpretability perspective. Using Grad-CAM heatmap visualization, we analyze the regions where the model focuses on detection targets. We propose a lightweight convolutional attention mechanism, LCA (Lightweight Convolution Attention), which significantly enhances YOLOv7's attention to elongated targets while reducing the impact of columnar interference. This improves both the model’s robustness and interpretability. Experimental results show that LCA outperforms classical attention modules such as SE, ECA, and CA, while maintaining a minimal parameter size. Specifically, the mAP of the extremely elongated and challenging sample ``operatingbar" increased by 4.4\%, and the mAP of the small target ``wrongglove" improved by approximately 2\%. This makes LCA well-suited for detecting elongated targets in complex power operation environments. }
}


@InProceedings{mlic25-57,
    title = {Competitive Influence Maximization Across Social Networks},
    author = {Yang, Ruisi and Bu, Chunfen and Yue, Qiang and Jiang, Xing and Ma, Qiangnan and Zhang, Yunfei},
    pages = {511-518},
    abstract = { The proliferation of Web 2.0 technologies has significantly reshaped information propagation dynamics across social media platforms. While existing studies extensively analyze influence maximization within single-platform environments, competitive propagation dynamics across multiple interconnected social networks remain underexplored. Addressing this research gap, we define the Competitive Influence Maximization Across Social Networks (CIMASN) problem and introduce a novel Competitive Independent Cascade Model (CICM) that incorporates competitive influences propagating simultaneously across multiple platforms. A greedy algorithm is proposed for effective seed node selection under this competitive scenario, validated through extensive experiments on both real-world and synthetic datasets. Results demonstrate that our model and algorithm significantly outperform traditional approaches, highlighting the necessity and effectiveness of modeling competitive propagation dynamics across multiple social networks.}
}


@InProceedings{mlic25-58,
    title = {Semi-Supervised L2KC (S-L2KC) Classifier},
    author = {Lv, Yue},
    pages = {519-526},
    abstract = {Building upon the density difference paradigm, a novel kernel classifier distinct from Support Vector Machines (SVM) — the L2-norm Kernel Classifier (L2KC) — has been developed. This methodology establishes an integrated squared error(ISE) criterion to estimate the true ${{d}_{\gamma }}\left( x \right) $ through minimizing the L2-distance between ${{d}_{\gamma }}\left( x \right) $ and ${{\overset{\scriptscriptstyle\frown}{d}}_{\gamma }}\left( x \right) $, thereby achieving classification via explicit density difference representation. While L2KC demonstrates comparable accuracy to SVM with enhanced decision efficiency, its performance on real-world semi-supervised datasets requires improvement. To address this limitation, we propose the Semi-supervised L2KC (S-L2KC) by incorporating a locality-preserving projection (LPP) based manifold regularization term into the L2KC objective function. This integration effectively enforces the manifold assumption. Experimental results on benchmark datasets from the UCI and LIBSVM demonstrate that compared to L2KC, the proposed S-L2KC exhibits superior generalization capability, characterized by higher mean test accuracy with comparable or even smaller variance.}
}


@InProceedings{mlic25-59,
    title = {A Comparative Study of Several Different Neural Network Approaches for Information Security Modeling},
    author = {Xie, Jiahui and Li, Junpeng and Qiu, Ping},
    pages = {527-533},
    abstract = {In the rapid development of the Internet, people's lives have been deeply bound to the Internet, and the network information data is explosive growth. However, along with it, there is an increasingly serious problem of network information security. In order to achieve more accurate network information security classification judgment, we use BP neural network, RBF neural network, based on genetic algorithm optimization of RBF neural network three models to compare the information security model respectively, used to assess their ability to assess the information security risk (threatening, vulnerability, asset identification). The experimental results show that the RBF neural network optimized based on genetic algorithm has higher accuracy and lower error in information security risk assessment, which has significant advantages over the traditional neural network and provides a strong basis for improving the level of information security protection and selecting the best neural network model.}
}


@InProceedings{mlic25-60,
    title = {Equivalent Modelling and Simulation Method for 2.5D Chips Based on Machine Learning and Multi-Physics Field Coupling},
    author = {Yuan, Quan},
    pages = {534-542},
    abstract = {Aiming at the problems of low computational efficiency and high resource consumption of traditional finite element simulation owing to complex structures such as through-silicon vias (TSVs) and bumps in 2.5D chip packages, this paper proposes an intelligent equivalent modelling and simulation optimization method that integrates machine learning and multi-physics field coupling. By constructing a dynamic equivalent model adaptive mechanism and adjusting the material parameters in real time based on deep neural network to capture the temperature-stress coupling effect; combining with the multi-scale geometry simplification technology, the deep learning is used to identify the key regions and differentially assign the modelling accuracy, which reduces the overall mesh number by 50\% while ensuring the refined simulation of key regions (e.g., heat-sensitive and stress-concentrated regions). Dynamic model reconstruction and real-time optimization under multi-physics field coupling are further achieved through the integration of sensor data and simulation feedback. The experimental results show that compared with the traditional finite element method, the method shortens the simulation time by more than 30\%, reduces the memory consumption by 50\%, reduces the root mean square error (RMSE) of the temperature field by 2.8°C, and controls the maximum error of the stress field within 4.8\%, which significantly improves the multi-physics simulation efficiency and accuracy of the complex 2.5D chip package and provides a highly efficient and reliable solution for the design optimization of high-density integrated chips. solution for the design optimization of high-density integrated chips.}
}


@InProceedings{mlic25-61,
    title = {Dispersive optical solitons of the stochastic Fokas-Lenells equation with multiplicative white noise based on the trial equation method},
    author = {Guo, Shiyi},
    pages = {543-549},
    abstract = {In this paper, we study the Fokas-Lenells (FL) equation with multiplicative white noise in the Itô sense for polarization-maintaining fibers, using the trial equation method and the polynomial complete discriminant system approach. All exact solutions of the equation in its general form are obtained, including solitary wave solutions, trigonometric function solutions, rational solutions, and Jacobian elliptic function doubly periodic solutions. Furthermore, several representative numerical simulation results are presented under given parameter conditions.}
}




@InProceedings{mlic25-62,
    title = {Optimizing the Path of AIGC Creative Content Generation Based on Large Language Models and Knowledge Graphs},
    author = {Cao, Yushu},
    pages = {550-559},
    abstract = {With the rapid development of generative artificial intelligence (AIGC) technologies, creative content generation using large language models (LLMs) and knowledge graphs (KGs) has become a key area of research. However, current methods often fail to fully harness the semantic enhancement capabilities of knowledge graphs in the content generation process. To address this gap, this paper proposes an innovative creative content generation path optimization model, KG-GPT-opt, which integrates large language models with knowledge graphs. Experimental results demonstrate that the KG-GPT-opt model outperforms traditional baseline models across several standard evaluation metrics, achieving improvements of 6.4\%, 7.5\%, and 4.8\% in BLEU, ROUGE-L, and METEOR, respectively. Furthermore, the model receives high expert ratings of 8.6 and 8.8 for creativity and coherence, surpassing other generation models. This study offers a novel approach for the AIGC field, advancing the integration of large language models and knowledge graphs, and broadening the potential applications of intelligent content generation in areas such as cultural creativity and smart marketing.}
}



@InProceedings{mlic25-63,
    title = {WAFUzz:A Fuzz-based WAF protection function testing technology},
    author = {Mao, Enhui and Li, Danbo and Yan, Xuexiong},
    pages = {560-572},
    abstract = {Web Application Firewalls (WAFs) are designed to detect and intercept potentially malicious HTTP requests, thereby protecting web applications from various attacks. However, if the WAF's rule set and detection strategy are flawed, its protection function may fail under certain conditions, making it difficult to ensure comprehensive application security. Existing WAF protection testing methods either rely on fixed attack payload datasets, which may lead to inefficient testing due to dataset limitations, or use machine learning to pre-train adversarial WAF models, which are not suitable for testing WAF services deployed in the real world.

To address this issue, we propose a new WAF evaluation technique based on fuzz testing. This method uses context-free grammars to generate diverse attack payloads and combines Monte Carlo Tree Search (MCTS) to optimize mutation paths, thereby achieving systematic testing of WAF defense measures. Specifically, we predefine context-free grammars for SQL injection (SQLi) and cross-site scripting (XSS) based on expert knowledge to generate the initial input for fuzz testing and serve as seed payloads for subsequent mutations. Then, MCTS guides the mutation process by dynamically adjusting node weights to prioritize the exploration of promising paths, thereby improving test efficiency and effectiveness.

Experimental results show that our approach reduces the protection failure rate of SQLi and XSS to 48.80\% and 37.80\%, respectively, outperforming benchmark tools such as WAF-A-MOLE and SqlMap. In addition, the invalid payload rate is also reduced to 5.63\% and 6.72\% for SQLi and XSS, and the number of WAF queries is reduced by more than 22 times, demonstrating the excellent evaluation efficiency of our approach.}
}

@InProceedings{mlic25-64,
    title = {FRE-Based Sparrow Search Algorithm for Green Flexible Job Shop Scheduling},
    author = {Xue, Ziming and Zhou, Jun},
    pages = {573-586},
    abstract = {The modern manufacturing is facing the challenge of energy saving and emission reduction. This study addresses the Multi-objective Green Flexible Job-shop Scheduling Problem (MGFJSP) with three objectives makespan, machine workload and carbon emissions, a Fuzzy Relative Entropy (FRE)-based improved Sparrow Search Algorithm (FISSA) is proposed. FISSA begins with special initialize methods to ensure a uniform distribution in solution space. Next, a logarithmic spiral is introduced in scroungers to enhance global search capability. Additionally, an insertion strategy is implemented to reduce machine idle time and carbon emissions. Finally, a FRE coefficient is introduced, where solutions are evaluated by comparing them with the ideal point, diversity is quantified, and selection is guided. Experimental results confirm that FISSA outperforms other multi-objective algorithms, significantly minimizing processing time and carbon emissions, demonstrate superior robustness and convergence.}
}




@InProceedings{mlic25-65,
    title = {R-PBFT: Efficient DAG-based consensus Algorithm for Internet of Vehicles},
    author = {Niu, Kedong and Cao, Yangjie and Li, Jie},
    pages = {587-594},
    abstract = {With the increase in the number of vehicles in residential households, the traffic flow on roads has shown a significant growth trend, which places higher demands on the capacity of vehicular networks. It is worth noting that the traditional PBFT algorithm experiences a significant decline in consensus efficiency as the number of nodes increases, which may pose a key constraint on the information exchange efficiency in vehicular networks. Based on this, this study proposes an R-PBFT consensus algorithm based on DAG blockchain. This algorithm optimizes the consensus mechanism and significantly improves the information transmission rate between roadside units and vehicles. Experimental results show that, compared to traditional consensus algorithms, the proposed solution effectively improves consensus efficiency while reducing communication costs.}
}



@InProceedings{mlic25-66,
    title = {Reinforcement Learning Based Collaborative Path Planning Research for UAVs and Unmanned Vehicles},
    author = {Li, Xuanran and Yao, Longxin and Li, Mingzhe and Zhang, Bo},
    pages = {595-603},
    abstract = {This paper presents a reinforcement learning framework for multi-UAV and UGV coordinated path planning with charging constraints. We formulate the problem as a Markov Decision Process and develop a Transformer-based solution combining encoder-decoder architecture with policy gradients to optimize path synchronization and charging coordination. Experimental results demonstrate that our approach outperforms existing heuristic methods (GLS, TS) in terms of solution quality and generalization across different problem scales. The proposed method effectively minimizes mission completion time while handling energy constraints through intelligent charging point synchronization.}
}



@InProceedings{mlic25-67,
    title = {HD-MF: Hierarchical Dynamic-aware Multimodal Fusion for Fine-Grained Bird Recognition},
    author = {Li, Junjing and Liu, Xing and Luo, Jiu},
    pages = {604-613},
    abstract = {Fine-grained bird recognition plays a crucial role in biodiversity monitoring. Its primary challenge lies in identifying subtle inter-class visual differences and overcoming the inherent limitations of unimodal information. Audio provides crucial complementary cues, yet audiovisual fusion still faces challenges such as the semantic gap. To address these challenges, this paper proposed a hierarchical dynamic-aware multimodal fusion (HD-MF) architecture. This architecture captures locally aligned cross-modal features via its Cross-modal Spatial Interaction Module, extracts global high-order cross-modal correlations using the Factorized Bilinear Fusion Module, and dynamically integrates the outputs of these two fusion approaches through a Dynamically Adaptive Gated Fusion Unit. Evaluated on AViS, a paired audiovisual dataset constructed for this study, HD-MF achieved state-of-the-art performance. Experimental results demonstrated that HD-MF effectively integrates audiovisual complementary information, providing a novel and effective approach for enhancing fine-grained bird recognition performance.}
}


@InProceedings{mlic25-68,
    title = {JSOSAL: Joint Sampling for Open-Set Active Learning},
    author = {Zhang, Yongxiang and Zhang, Bo and Dai, Zhiqiang and Cao, Yangjie},
    pages = {614-621},
    abstract = { Traditional active learning methods typically operate under closed-set assumptions, where unlabeled data samples are selected for annotation from a pool consisting exclusively of known classes. However, real-world scenarios predominantly exhibit open-set conditions, characterized by the presence of substantial unknown-class instances within datasets. This fundamental discrepancy renders most conventional active learning approaches ineffective in practical applications.To address the annotation challenge in open-set environments, we propose JSOSAL (Joint Sampling for Open-Set Active Learning), an innovative approach that applies a Bayesian Gaussian Mixture Model (BGMM) to represent the probability distribution of the highest activation values, enabling effective discrimination between known and unknown classes. Our method subsequently selects high-entropy samples from the identified known-class subset for annotation. Rigorous testing on CIFAR-10 and CIFAR-100 shows that JSOSAL achieves superior performance compared to existing leading methods.}
}



@InProceedings{mlic25-69,
    title = {A Quantum Game Model and Simulation Study on Collaborative Operation of Container Sea-Rail Intermodal Transport},
    author = {Zhao, Yufeng and Zhao, Fuyang and Guo, Zhida},
    pages = {622-631},
    abstract = {Under the new development pattern of ``double circulation" and the continuous promotion of the Belt and Road Initiative, the demand for container sea-rail intermodal transport is increasing day by day, and the efficiency and stability of its collaborative operation become the key. This paper focuses on this, and constructs a quantum game model for the coordinated operation of container sea rail intermodal transport. The model brings the relevant stakeholders such as shipping enterprises and railway transport enterprises into the game framework, and analyzes the benefits under different strategy combinations. Through the design of simulation experiments, the model is verified. The results show that this model can accurately describe the decision-making behavior and synergy effect of various stakeholders, provide a new theory and method for optimizing the collaborative operation of sea rail intermodal transport, and help to improve the overall operation efficiency and service level.}
}


@InProceedings{mlic25-70,
    title = {Dynamic Trading Strategies for Volatile Assets: A Hybrid GM-LSTM Model with Finite State Machine Optimization},
    author = {Sun, Haoran and Song, Bohan and Cong, Meng and Wang, Zeran and Liu, Zexian and Wang, Xueru and Han, Yujie and Cui, Xinqi},
    pages = {632-643},
    abstract = {This study addresses the challenge of predicting investments in highly volatile assets, such as gold and ancient coins, by proposing a hybrid forecasting strategy that integrates the Grey Model (GM), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). A finite automaton-based trading decision model is developed to enable rapid decision-making in dynamic market environments. Traditional methods often struggle to adapt to the unpredictability of such assets, prompting the need for advanced predictive frameworks. The methodology encompasses data preprocessing, model training, and validation, with a focus on optimizing short- and long-term forecasts. Experimental results demonstrate that the hybrid GM-LSTM strategy significantly enhances prediction accuracy: GM excels in short-term forecasting (first 200 days) due to its efficiency with limited data, while LSTM outperforms in long-term scenarios by capturing complex temporal dependencies. A dynamic weight adjustment mechanism, incorporating profit (PI) and risk indices (RI), balances returns and risks. Sensitivity analysis reveals the model’s robustness under varying transaction costs (0.1\%–10\%), maintaining profitability even at higher cost levels. Key performance metrics—annualized return, Sharpe ratio, and maximum drawdown—validate the strategy’s superiority over benchmarks like buy-and-hold. The state machine-driven trading model, evaluated through Value at Risk (VaR) and sliding window protocols, ensures adaptability across market conditions. This work provides traders with a data-driven decision-making tool, optimizing investment strategies while mitigating risks in volatile markets.}
}



@InProceedings{mlic25-71,
    title = {Trust-Region Bayesian Optimization for High-Dimensional Black-Box Problems: Integrating Deep Kernel Learning with Adaptive Gradient Mechanisms},
    author = {Yang, Guolin and Qin, Hua and Fu, Yanming},
    pages = {644-659},
    abstract = {The traditional Bayesian optimization (BO) algorithm faces significant performance bottlenecks when addressing high-dimensional black-box optimization problems. To mitigate this challenge, the present paper introduces a novel trust region Bayesian optimization algorithm. Firstly, in the design of the BO surrogate model, we employ a combination of deep neural networks and kernel methods to enhance the Gaussian process regression (GPR) model. This approach improves GPR's capacity to identify and fit the nonlinear characteristics of black-box functions while also increasing regression accuracy. Secondly, in formulating the BO acquisition function, an adaptive gradient trust region adjustment method is utilized to bolster BO's search capabilities within high-dimensional solution spaces. Concurrently, a hybrid sampling strategy is implemented to generate more diverse sampling points, thereby enhancing BO’s ability to escape local optima. The proposed algorithm has been validated on three 60D multimodal complex functions as well as two engineering application problems and compared with other advanced variants of BO. Experimental results demonstrate that our proposed algorithm exhibits superior iterative convergence, rapidly approaches optimal values for black-box problems with fewer function evaluations, and achieves higher computational accuracy. These findings confirm both the feasibility and effectiveness of the improved BO approach presented in this paper.}
}


@InProceedings{mlic25-72,
    title = {Confidence-Aware Contrastive Distillation for Test-time Prompt Tuning},
    author = {Wang, Min and Cheng, Qing},
    pages = {660-666},
    abstract = {Pre-trained vision-language models like CLIP have shown strong performance on various visual recognition tasks but often suffer from poor generalization under distribution shifts. Test-Time Prompt Tuning (TPT) is a promising solution that adapts prompt embeddings during inference using entropy minimization on unlabeled test data, while keeping the vision and text encoders frozen. However, entropy-based tuning lacks structural regularization and can lead to overconfident misclassifications. In this paper, we introduce Confidence-Aware Contrastive Distillation (CaCoD), a lightweight and effective approach to improve the robustness and calibration of TPT. Our method leverages the confidence structure of test-time predictions by identifying high- and low-confidence samples, and aligning their feature representations through a contrastive distillation loss. This encourages semantically meaningful updates to the prompt embeddings without requiring labels or retraining. Experiments across 11 fine-grained datasets demonstrate that CaCoD consistently reduces calibration error and improves predictive reliability, while maintaining strong accuracy. Our approach is model-agnostic and easily pluggable into existing TPT pipelines.}
}


@InProceedings{mlic25-73,
    title = {Rate-controllable Learned Image Compression Using Channel Attention},
    author = {Xie, Zhiwei and Zhang, Wenyu and Shao, Hua and Yang, Xianze and Zhang, Xiao},
    pages = {667-677},
    abstract = {Classical learned image compression (LIC) methods usually require training multiple models to achieve the best compression performances at different rates, which greatly increases their training and deployment cost. Though existing methods can realize rate variation by using channel scaling factors or transform of the Lagrange multiplier, they are not able to adaptively control the compression process with desired rates, which causes additional trial cost if we want to obtain results with given compression ratios. In this paper, we address this issue by employing channel attention modules that use the desired target bit-rate as side information to adjust the distributions of feature channels, and a new rate-distortion loss function that integrates the target bit-rate into the rate-distortion optimization framework is proposed to train the model to realize continuous rate control. Additionally, a two-stage training strategy is utilized to ensure that the network can adaptively adjust the bit-rates, at the same time achieving the best rate-distortion performance. Experimental results demonstrate that our method achieves effective rate control over a wide range of bit-per-pixels (BPPs).}
}

@InProceedings{mlic25-74,
    title = {A Spectrum Filtering Framework for Domain Generalization},
    author = {Li, Fuchao and Li, Kun},
    pages = {678-684},
    abstract = {Domain generalization aims to address the distribution shift problem inherent in neural networks, wherein a misalignment between test data distribution and training data distribution leads to significant performance degradation. This paper introduces Fourier Style Restitution (FSR), a Fourier-transform-driven method for domain generalization. FSR integrates the principles of Fourier augmentation and style disentanglement with feature reconstruction, enhancing model generalizability to unseen domains. The framework implements a cross-domain filtering enhancement strategy based on Fourier transform, leveraging frequency domain filtering to bolster model robustness against distributional variations. Through this paradigm, each sample transcends source domain constraints to derive optimized domain-invariant feature representations tailored to its intrinsic characteristics. The framework further incorporates style regularization to distill consistency signals from stylized images and employs prototype compensation to recover lost domain-invariant features. Extensive experiments demonstrate state-of-the-art performance on benchmark datasets. The method's efficacy stems from feature enhancement and style reconstruction through Fourier-based operations for robust domain generalization.}
}



@InProceedings{mlic25-75,
    title = {Survey on Path Planning Based on Deep Reinforcement Learning},
    author = {Xu, Lihan and Zhang, Wenzhi},
    pages = {685-695},
    abstract = { In recent years, deep reinforcement learning (DRL) has demonstrated significant potential in the field of path planning and control, offering breakthrough solutions for path planning in dynamic and complex environments. DRL has been widely applied in UAV obstacle avoidance, autonomous vehicle path optimization, multi-robot coordination, and complex terrain navigation, demonstrating ad-vantages such as superior path quality, improved smoothness, and enhanced safety. This paper provides a systematic review of recent advances and applications of DRL core techniques. Value-based methods (e.g. DQN) significantly improve decision-making efficiency through optimized reward design and network architectures. Policy gradient algorithms (such as PPO, DDPG, and TD3) achieve high-precision control in continuous action spaces. The Actor-Critic framework, combined with double Q-networks and delayed update mechanisms (e.g. TD3), further expands the application scenarios. Future research should focus on enhancing cross-scenario generalization capabilities and improving deployment efficiency at the industrial level, thereby promoting the practical application of DRL in autonomous driving and industrial robotics.}
}



@InProceedings{mlic25-76,
    title = {Study on Time-Sensitive Targets Strike Path Planning Based on Improved Crayfish Optimization Algorithm},
    author = {Wang, Yalong and Shi, Xianming and Yang, Mifen and Liu, Penghua and Zhao, Qian},
    pages = {696-706},
    abstract = {Addressing the challenges of complex solution and low accuracy in time-sensitive targets strike path planning, this paper proposes a novel path planning method which, based on the Open Vehicle Path Problem (OVRP), builds a model and applies the Improved Crayfish Optimization Algorithm (ICOA) to solving it. Relative to the initial Crayfish Optimization Algorithm (COA), the ICOA employs an improved strategy, namely ``Chaos Accumulation-Environment Awareness-Lens Imaging” to markedly enhance the optimization efficiency and robustness of the algorithm and, through integer coding and crossover operation, is integrated with a Genetic Algorithm (GA) and innovatively applied to addressing the OVRPs. The experimental results demonstrate that ICOA exhibits better convergence speed and optimization accuracy over the other algorithms in composite optimization, displays enhanced robustness, and is capable of rapidly generating a path planning scheme with a shorter total flight distance in the OVRP model, further verifying the effectiveness of ICOA in solving the OVRPs.}
}



@InProceedings{mlic25-77,
    title = {Local Hurst index timing strategy},
    author = {Shi, Qingzheng and Li, Wenzhuo and Wang, Jincheng and Zhang, Xuezhen and Zou, Hui},
    pages = {707-716},
    abstract = {This paper proposes a technical analysis strategy based on the Hurst index to predict stock price trends in uncertain markets. As a robust timing tool requiring minimal assumptions, the Hurst index effectively captures market memory effects. We apply this method to the CSI 300, mathematically analyze its properties, and empirically validate its profitability.}
}


@InProceedings{mlic25-78,
    title = {Uncovering the Secrets of Momentum Hidden in the Game of Tennis},
    author = {Huo, Haoqian},
    pages = {717-725},
    abstract = {Advances in sports technology have had a profound impact on the tennis game, not only improving the fairness and enjoyment of the game, but also changing the way players are trained and performance analyzed. This article builds a momentum evaluation model and deeply explores the impact of momentum on game results based on the game data set.

Before building the model, we cleaned and standardized the given data and classified it into four parts: fatigue level, psychological state, personal technical ability, and real-time conditions. Preliminary preparations were made for the construction and solution of the model.

We developed a comprehensive tennis player ``momentum” evaluation model using Logistic-LGBM, employing point granularity and five-fold cross validation. This model dynamically assesses and captures real-time changes in player momentum. Our real-time visualization during the 2023 Wimbledon men’s singles final revealed observable momentum trends. However, due to the complexity of factors affecting player scores, not accounting for them introduced significant noise and disrupted player scores. This insight serves as a foundation for refining the model.}
}



@InProceedings{mlic25-79,
    title = {Modeling and Analysis of Olympic Medal Table Based on Multiple Features},
    author = {Chen, HanBang and Kong, Delin and Jin, Biao and Huang, CaiLing and Ke, YiXiang and Zhang, MingCheng and Li, GuanHua and Tan, Chao},
    pages = {726-733},
    abstract = {In the first part, this study first used the winning records and medal data of Olympic competitions. Based on the relevant variation characteristics of medal counts, their impact was assessed by quantifying the fluctuation of medal counts under multiple characteristics. For medal counts, they were incorporated into a medal prediction model under time series through stacked integration. LR, LASSO, SVM, and Catboost were used as base leaners in the first layer ; RF, XGBoost, and LightGBM were used in the second layer of the meta-learner; and the optimal stacked integration learning for medal count prediction under time series was subsequently determined. Subsequently, the medal standings for the 2028 Summer Olympics in Los Angeles, USA were predicted under dynamic simulation as the entire sequential system was varied. Based on the parameter-adjusted feature structure of countries without medal counts, two evaluation models were constructed, one of which was initialized with a fixed medal-associated parameter ratio. According to the model framework, the impact of no medal data is parameterized according to the model parameter distribution law to complete the analysis of countries with no medal counts.}
}




@InProceedings{mlic25-80,
    title = {Explainable Deep Neural Network for Lung Squamous Cell Carcinoma Survival Analysis by Integrating Genomic and Clinical Data},
    author = {Zhou, Xudan and Yang, Qinglin and Zhang, Yuxin and Hou, Yanyan and Chen, Changlong and Ma, Guohui and Luo, Jin and Shu, Wei},
    pages = {734-746},
    abstract = {we utilized explainable deep learning methodologies to elucidate critical genes and prospective biomarkers correlated with the prognosis of Lung Squamous Cell Carcinoma (LUSC). Transcriptomic data were systematically acquired from the TCGA repository and underwent comprehensive differential expression profiling to identify candidate genes warranting in-depth exploration. We developed Cox-PASNet, a pathway-aware deep learning model designed to predict survival outcomes in lung squamous cell carcinoma (LUSC) by integrating multi-modal data, including clinical variables, transcriptomic profiles, and curated biological pathways. The model demonstrated robust performance, achieving an AUC of 0.73 in stratifying patients into long- and short-term survival groups. Beyond predictive accuracy, Cox-PASNet offers interpretable insights into key molecular pathways, facilitating the discovery of novel prognostic biomarkers (CCDC181, B2M, BTD, C1orf112, ANAPC7) and their related biological pathways (regulation of cell cycle, DNA repair, cytoskeletal dynamics, tumor microenvironment, and metastasis) associated with LUSC survival. The significance of these genes was validated using external datasets and clinical indicators. Notably, members of the CCDC family were particularly important, with many found to enhance tumor cell proliferation. Elevated expression levels of CCDC proteins demonstrated a significant correlation with adverse clinical outcomes, including diminished overall survival rates and unfavorable prognosis. In summary, through interpretable deep learning and bioinformatics approaches, we identified several relevant genes, with CCDC genes being closely linked to LUSC survival.}
}



@InProceedings{mlic25-81,
    title = {HBADTI: Drug-target interaction prediction based on multi head attention and bidirectional cross attention},
    author = {Zhao, Jiaming},
    pages = {747-759},
    abstract = {The study of drug-target interactions (DTIs) holds critical importance in the drug development process. The core challenge in DTI prediction lies in accurately capturing the features of both drugs and proteins, as well as thoroughly understanding their interaction mechanisms. In light of this, we developed an end-to-end DTI prediction model called HBADTI. The model employs graph convolutional networks to encode drug features. For protein feature extraction, we designed a dedicated feature extraction module (ESAM) that combines convolutional neural networks (CNNs) with multi-head self-attention mechanisms to effectively capture protein sequence characteristics. Subsequently, a bidirectional cross-attention network is utilized to integrate the features of both drugs and proteins, followed by a multilayer perceptron to classify unknown drug-target pairs.Comparative experimental results demonstrate that HBADTI outperforms multiple baseline methods. Ablation studies further confirm that both the bidirectional attention network and the ESAM module significantly contribute to the improvement of DTI prediction performance.}
}


@InProceedings{mlic25-82,
    title = {GANFL: A log anomaly detection method based on collaborative optimization of federated learning and generative adversarial networks},
    author = {Yao, Longxin and Li, Xuanran and Li, Mingzhe and Zhang, Bo},
    pages = {760-767},
    abstract = { With the rapid development of information technology, the amount of data is growing explosively. Enterprises and society have an increasing demand for data storage, processing and analysis. Data centers have emerged as the times require. They can centrally manage massive amounts of data, provide efficient computing and storage capabilities, meet the high requirements of different industries for data processing, and ensure data security and reliability. In data centers, numerous devices, systems and applications continuously generate a large number of logs during operation. These logs record the activities and status information at all levels of the data center, including the operating status of the server, the traffic of network devices, and the operation records of applications. Log anomalies refer to the presence of records that do not conform to normal patterns or expected content in the log files that record the operating system's own operating events. Log analysis can help developers quickly locate the source of the fault. By analyzing the log data, they can determine the device where the fault occurred and the cause of the fault. At the same time, they can also conduct advance analysis based on the existing log data to discover potential problems.In this paper, the method of co-optimization of GAN and federated learning is adopted, which not only solves the problem of data silos, but also solves the problem of insufficient data.}
}


@InProceedings{mlic25-83,
    title = {MEFN: A Multi-scale Entropy-aware Fusion Network For Image-Text Retrieval},
    author = {Liu, Jinjin and Fan, Changchang},
    pages = {768-778},
    abstract = {Image-Text Retrieval(ITR), a crucial task in multi-modal learning, aims to achieve cross-modal information retrieval through semantic alignment and matching between images and text. With the advancement of deep learning, significant progress has been made in the accuracy and efficiency of ITR methods. However, existing approaches still face challenges such as modality heterogeneity, information redundancy, and insufficient multi-scale feature alignment between images and text. To address these issues, this paper proposes an Image-Text Retrieval method based on a Multi-scale Entropy-aware Fusion Network (MEFN). By introducing entropy-aware modeling and multi-scale attention mechanisms, this method enhances the correlation between image and text features, further improving cross-modal semantic matching capabilities. Specifically, MEFN first guides the fusion of image and text features through an entropy-aware model, then finely models multi-scale features using local and global attention mechanisms to generate efficient image-text fusion representations. Experimental results demonstrate that MEFN significantly improves the accuracy and robustness of image-text retrieval compared to mainstream methods on benchmark datasets such as Flickr30K and MSCOCO, especially showing superior performance in fine-grained object matching and complex scenarios. This study provides a new perspective for image-text retrieval methods and holds promise for further applications in multi-lingual image-text retrieval and video-text retrieval fields. }
}



@InProceedings{mlic25-84,
    title = {A Knowledge Augmented Framework for Multimodal News\\ Object-Entity Relation Extraction},
    author = {Li, PeiLing and Li, Lin},
    pages = {779-788},
    abstract = {Multimodal relation extraction, as an important research direction in the field of information extraction, aims to identify entities and objects from both text and images and establish cross-modal semantic associations. Current mainstream methods still face challenges in handling complex multimodal data, such as semantic alignment confusion and redundant associations, which lead to erroneous associations between irrelevant entities and objects, severely affecting system performance. To address this issue, this paper proposes a multimodal relation extraction framework that integrates knowledge graphs. This approach uses the knowledge graph as external semantic support to filter candidate entity-object pairs through structured semantic information, and leverages a multimodal alignment module to achieve precise semantic matching. Experimental results show that this method significantly outperforms existing methods on multiple benchmark datasets, especially in fine-grained relation recognition, where the F1 score increases by 4 percentage points, effectively demonstrating the framework's ability to mitigate cross-modal noise interference.}
}


@InProceedings{mlic25-85,
    title = {A Functional Area Layout Model of Agricultural Products Logistics Park Based on PSO Algorithm},
    author = {Zhao, Wanning and Zhao, Fuyang},
    pages = {789-797},
    abstract = {This paper proposes a functional area layout model for an agricultural products logistics park based on particle swarm optimization ( PSO ). Targeting the the layout planning of an agricultural products logistics park in C County, a multi-objective planning model is established ,considering the total material handling cost, land area utilization rate, and the comprehensive correlation of functional areas. The PSO algorithm is employed to solve the model and obtain the optimal layout scheme. Through field research and data analysis, the validity and practicability of the model are verified. The results indicate that the model can significantly enhance the operational efficiency and service quality of agricultural products logistics parks, reduce logistics costs, and promote the sustainable development of the agricultural products logistics industry.}
}



@InProceedings{mlic25-86,
    title = {A Hybrid XGBoost and Stacked Regression Model with Optimized Feature Selection for Port Throughput Prediction},
    author = {Ding, Ning and Zhao, Fuyang and Wang, Xiaoyu},
    pages = {798-807},
    abstract = {The prediction of port throughput is very important for port operation management. Aiming at the prediction of port throughput, this study selected the level of economic and trade and development vitality in the hinterland, regional transportation capacity in the hinterland, port infrastructure conditions and other first-class indicators and 13 second-class indicators, used xgboost to analyze the importance of characteristics, and screened out 9 key influencing factors. The combined model based on xgboost and stacking algorithm was constructed, and the parameters were optimized by cross validation and grid search method. Taking Dalian port as an example, the experiment shows that when xgboost stacking model is used to predict port throughput, MAE, MAPE and RMSE are the lowest, and $R^2$ is the highest. The prediction performance is significantly better than other models, which verifies the effectiveness and superiority of the model in port throughput prediction, and provides a new method and idea for port throughput prediction.}
}



@InProceedings{mlic25-87,
    title = {Research on Chinese Text Similarity by Fusing Deep and Shallow Features},
    author = {Lu, Chengfang and Li, Gang and Hou, Linjie},
    pages = {808-818},
    abstract = {Existing Chinese text similarity calculation methods typically focus on a single dimension, resulting in insufficient information integration and difficulty in comprehensively merging semantic, feature, and structural information. To address this issue, a Chinese text similarity calculation model that integrates deep and shallow similarities has been proposed. The model first utilizes a Siamese neural network to obtain dynamic vector representations of the texts, further extracting features and calculating deep semantic similarity. Next, based on traditional edit distance algorithms, an improved component-weighted edit distance algorithm is designed by introducing tokenization and assigning weights to different parts of speech, to more accurately reflect the lexical-level shallow features and structural information of the texts. Finally, by linearly weighting and fusing deep semantic similarity with shallow feature similarity, a more comprehensive text similarity evaluation is achieved. Experimental results show that in experiments based on Chinese STS-B and Chinese SICK datasets, the Spearman correlation coefficients improved by 4.34 and 3.76, respectively, compared to the baseline model Siamese-RoBERTa. This model effectively enhances the performance of Chinese short text similarity calculation and better aligns with the expression habits of Chinese texts.}
}



@InProceedings{mlic25-88,
    title = {An optimization problem Based on Integer Programming Theory},
    author = {Wang, Hui and Ji, Xiaoqing and Sheng, Quanbo and Zhao, Jingjing and Wang, Mengwei},
    pages = {819-825},
    abstract = {With the implementation of the rural revitalization strategy, promoting high-quality rural development has become a strategic requirement. A key challenge in optimizing rural development is achieving high-quality agricultural cultivation. Given fixed arable land areas and seed quality, determining optimal crop planting strategies is a critical research focus. This study takes a village in North China's mountainous region as an example, incorporating local land types, suitable crops, terrain areas, and infrastructure (traditional greenhouses and smart greenhouses). First, land is classified based on given data. Second, yields, planting costs, and sales prices of the same crop across different terrains are analyzed, with median prices used for profit comparisons. Finally, using integer programming principles and intelligent software, an optimal planting strategy for 2024 is proposed through yield models, planting area models, and maximum revenue models.}
}



@InProceedings{mlic25-89,
    title = {Evolution of Bitcoin Trust Communities},
    author = {Cao, Yuemin},
    pages = {826-835},
    abstract = {Bitcoin, a digital currency facilitated by blockchain technology, enables direct exchange and personal ownership of digital assets, verified through mathematical consensus. This paper explores and analyzes transaction data within the Bitcoin network, with a focus on improving the efficiency of entity recognition methods and identifying illegal transaction patterns. We begin by introducing Bitcoin's development background, underlying principles, and transaction processes. We then delve into the structure of Bitcoin transaction data and review recent literature on its analysis, summarizing key technologies and research directions. To address the inefficiencies of traditional heuristic entity recognition methods, we propose an innovative solution that establishes entity relationship sets and utilizes active address data. Our approach introduces specific advancements, including a novel algorithm designed to enhance network connectivity and stability, and a centrality aggregation index that outperforms traditional node centrality indices. This algorithm facilitates quick reconnection to previously successful peer nodes, discovers new nodes upon connection loss, and propagates node information across the network for more stable connections. Additionally, it employs a seed node mechanism to expedite network discovery. Our method leverages a core data structure that maintains a list of peers for initial connections, automated through a seed node process. This bootstrapping mechanism allows Bitcoin clients to efficiently connect to the entire Bitcoin network. For implementation and analysis, we utilize NetworkX, a Python package for manipulating and investigating complex networks. We visualize the network structure using the number of transactions or reviews as node size, average review sentiment as node color, review mistrust as edge length, and a force-directed algorithm for node positioning. Our results demonstrate that the first-order aggregation centrality index performs better than the node centrality index, confirming that incorporating more information about first-order correlation attributes around a node enhances the model's effectiveness. Our proposed model, integrating the centrality aggregation index, achieves a 1\% improvement in precision, a 5\% improvement in recall, and a 4\% improvement in F1 score compared to the original feature set model. We define C as the node centrality feature set, C1 as the first-order aggregated feature set, C2 as the second-order aggregated feature set, and AF as the original feature set. From both model performance and visualization perspectives, the centrality aggregation index enables quick identification of key nodes and enhances the discovery of illegal transaction patterns in the network. By reversing and backtracking the capital flow path, our method can uncover more illegal transaction nodes and provide greater interpretability for the illegal transaction model. Finally, we discuss how to analyze and identify illegal behavior characteristics in Bitcoin transaction data, concluding with an examination of data sources, network construction, and analysis methods. By offering a comprehensive exploration of Bitcoin transaction data and advancing entity recognition methods, this paper provides valuable insights into the evolving landscape of cryptocurrency and blockchain technology. Our proposed innovations result in significant efficiency improvements and enhanced detection of illegal activities within the Bitcoin network.}
}
